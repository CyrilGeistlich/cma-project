<<<<<<< HEAD
---
title: The title of your Semesterproject
subtitle: A subtle subtitle
author: Cyril Geistlich and Micha Franz
output: html
---


<!-- You can add  your R Code with Code chunks-->

```{r}
#| echo: false
#| warning: false
#| message: false

# You can set chunk options individually per code chunk, as was done with this
# code chunk.

# echo: false           hides the code from the generated output
# warning: false        hides warnings from the generated output
# message: false        hides messages from the generated output

# To apply the setting for all code chunks, add the options to the yaml header of the document (in between the ---) without the preceeding "#|".

```


## Abstract


This project aims to investigate key factors and features in GPS tracking data to differentiate transportation vehicles. Machine learning is applied to automate transportation mode detection using spatial, temporal, and attribute analysis. Manual verification of results ensures accuracy. The findings contribute to computational movement analysis and automated transportation mode detection.

## Introduction

## Research Question

What are the key factors and features that can be extracted from GPS tracking data to differentiate between different types of transportation modes?
How can machine learning techniques be applied to GPS tracking data to automate the detection of the mode of transportation and which accuracies can be achieved by different machine learning algorithms?


## Material and Methods

<!-- the following is just a placeholder text, remove it!-->
Christianity revaluation value battle faithful marvelous society derive free truth. Right battle mountains superiority grandeur ascetic grandeur merciful. Derive against intentions burying salvation ocean. Right intentions dead victorious ideal spirit evil ultimate joy. Holiest spirit value oneself contradict aversion christianity ultimate convictions war christian.

## Results

<!-- the following is just a placeholder text, remove it!-->
Philosophy oneself passion play fearful self noble zarathustra deceptions sexuality. Endless ocean of oneself dead ocean. Selfish decrepit.

## Discussion

<!-- the following is just a placeholder text, remove it!-->
Justice convictions spirit sexuality insofar free marvelous joy. Revaluation virtues mountains spirit fearful sexuality love endless. Society intentions will noble burying aversion moral. Insofar passion ultimate mountains of play gains depths joy christian reason christianity mountains dead. Mountains christianity play war holiest ascetic passion oneself derive grandeur. Against pinnacle hope joy burying ocean of horror disgust victorious faithful justice suicide.


## Code
```{r}
library("dplyr")
library("sf")
library("readr") 
library("ggplot2") # to visualize data
library("mapview")
library("lubridate")
library("zoo") 
# library("caret") # Classification package
#CNN
library("neuralnet")
# library("keras")
# library("tensorflow")
```


# 1. Data Prep
## 1.1 Read Data

```{r read data}

# posmo_raw <- read.delim("data/posmo_26_05_2023.csv",sep=",")
# posmo_raw <- st_as_sf(posmo_raw,coords=c("lon_x", "lat_y"), crs = 2056)
#mapview(posmo_truth)

posmo_truth <- read.delim("data/posmo_full.csv",sep=",")
posmo_truth <- st_as_sf(posmo_truth, coords = c("lon_x", "lat_y"), crs = 4326) |>
   st_transform(posmo_truth, crs = 2056)

# Remove unwanted columns
posmo_truth <- posmo_truth[,-c(1,3,4)]

# Fix Timestamp
posmo_truth$datetime <- ymd_hms(posmo_truth$datetime) + hours(2)

#Ad ID to rows
posmo_truth <- posmo_truth |>
  mutate(id = row_number())


```


## 1.2 Clean Data (if necessary)?
## 1.3 Segmentation?
## 1.4 Calculate Movement Parameters
### 1.4.1 Speed/ Additional Moving Window Speed?

```{r Calc Diff_s, steplength, velocity}
#Create Coord Column
coords <- data.frame(st_coordinates(posmo_truth), posmo_truth$id)

#Calculate Time Difference between steps (diff_s), steplenght and velocity. 
posmo_truth <- posmo_truth |> 
  mutate(diff_s = as.numeric(difftime(lead(datetime),datetime))) |>
  mutate(steplength = ((coords$X - lead(coords$X))^2 + (coords$Y - lead(coords$Y))^2)^0.5) |>
  mutate(velocity = as.numeric(steplength/diff_s)) |>
  filter(diff_s != 0)

coords <- data.frame(st_coordinates(posmo_truth), posmo_truth$id)

#Calculate Moving Window Step length
posmo_truth <- posmo_truth |>
  mutate(
    step_mean = rowMeans(
      cbind(
        sqrt((lag(coords$X, 3) - coords$X)^2 + (lag(coords$Y, 3) - coords$Y)^2),
        sqrt((lag(coords$X, 2) - coords$X)^2 + (lag(coords$Y, 2) - coords$Y)^2),
        sqrt((lag(coords$X, 1) - coords$X)^2 + (lag(coords$Y, 1) - coords$Y)^2),
        sqrt((coords$X - lead(coords$X, 1))^2 + (coords$Y - lead(coords$Y, 1))^2),
        sqrt((coords$X - lead(coords$X, 2))^2 + (coords$Y - lead(coords$Y, 2))^2),
        sqrt((coords$X - lead(coords$X, 3))^2 + (coords$Y - lead(coords$Y, 3))^2)
      )
    )
  )


#Calculate Moving Window diff_s
posmo_truth <- posmo_truth |>
  mutate(diff_s_mean = as.numeric(difftime(lead(datetime,3),lag(datetime,3)))/6)


#Calculate Moving Window velocity
posmo_truth <- posmo_truth |>
  mutate(velocity_mean = as.numeric(step_mean/diff_s_mean))
 
# Delete Infitinte Values (is there better solution?)
#posmo_truth$velocity <- posmo_truth$velocity[!is.infinite(posmo_truth$velocity)]
coords <- data.frame(st_coordinates(posmo_truth), posmo_truth$id)
```

### 1.4.2 Acceleration /Moving Window?


```{r Acceleration}
#Acceleration stepwise
posmo_truth$acceleration <- posmo_truth$velocity/lag(posmo_truth$diff_s)

# Calculate acceleration using a moving window
posmo_truth <- posmo_truth |>
  mutate(
    acceleration_mean = rowMeans(
      cbind(
        lag(posmo_truth$acceleration,3),
        lag(posmo_truth$acceleration,2),
        lag(posmo_truth$acceleration,1),
        posmo_truth$acceleration,
        lead(posmo_truth$acceleration,1),
        lead(posmo_truth$acceleration,2),
        lead(posmo_truth$acceleration,3)
      )
    )
  )


```

### 1.4.3 Sinuosity /Moving Window?

```{r Sinuosity}
# Calculate Sinuosity using moving step_mean as path length and euclidean distance between


posmo_truth <- posmo_truth |>
  mutate(
    sinuosity = 
      ( # Path Length/Direct distance between first and last point
        sqrt((lag(coords$X, 3) - lag(coords$X, 2))^2 + (lag(coords$Y, 3) - lag(coords$Y, 2))^2) +
        sqrt((lag(coords$X, 2) - lag(coords$X, 1))^2 + (lag(coords$Y, 2) - lag(coords$Y, 1))^2) +
        sqrt((lag(coords$X, 1) - coords$X)^2 + (lag(coords$Y, 1) - coords$Y)^2) +
        sqrt((coords$X - lead(coords$X, 1))^2 + (coords$Y - lead(coords$Y, 1))^2) +
        sqrt((lead(coords$X, 1) - lead(coords$X, 2))^2 + (lead(coords$Y, 1) - lead(coords$Y, 2))^2) +
        sqrt((lead(coords$X, 2) - lead(coords$X, 3))^2 + (lead(coords$Y, 2) - lead(coords$Y, 3))^2)
      ) 
      / sqrt((lag(coords$X, 3) - lead(coords$X, 3))^2 + (lag(coords$Y, 3) - lead(coords$Y, 3))^2)
  )

```

### 1.4.4 Closeness to Traffic Network
### 1.4.5 Water Bodies (For boats)
### 1.4.6 Slope?
### 1.4.7 Average Distance between points in section
### FUrther Parameters!


## Clean Data
```{r}
# Replace NA values with a specified value (e.g., mean, median, or 0)
posmo_truth[is.na(posmo_truth)] <- 0  # Replace NA with 0


velocity_plot <- ggplot(posmo_truth, aes(id,velocity)) +
  geom_point() +
  ylab("velocity [m/s]")

acceleration_plot <- ggplot(posmo_truth, aes(id,acceleration)) +
  geom_point() +
  ylab("acceleration [m/s2]")

sinuosity_plot <- ggplot(posmo_truth, aes(id,sinuosity)) +
  geom_point()

ggsave("plots/velocity_plot.png", plot = velocity_plot, width = 8, height = 6, dpi = 300)
ggsave("plots/acceleration_plot.png", plot = acceleration_plot, width = 8, height = 6, dpi = 300)
ggsave("plots/sinuosity_plot.png", plot = sinuosity_plot, width = 8, height = 6, dpi = 300)
```

```{r}
posmo_truth <- posmo_truth[posmo_truth$velocity < 250,]
posmo_truth <- posmo_truth[posmo_truth$sinuosity < 5,]
posmo_truth <- posmo_truth[posmo_truth$acceleration < 20,]
posmo_truth <- posmo_truth[posmo_truth$diff_s < 1000,]
```


# 2.PCA?


# 3. Categories
Stationary?
Walk (Running?)
Bike
Train
Tram
Bus
Car
Skateboard
Scooter
Boat
Other

# 4. Cluster

# 5. Random Forest (RF)
```{r RF}
```


# 5. ANN
```{r Convolutional Neural Network (CNN)}
# We use a CNN, because it produces good results in pattern recognition

# Remove Points with no transport_mode tag

posmo_truth <- posmo_truth[posmo_truth$transport_mode != "", ]
posmo_truth <- posmo_truth[posmo_truth$transport_mode != "Other1", ]
#Remove any columns with strings
posmo_cnn <- st_drop_geometry(posmo_truth)
posmo_cnn <- posmo_cnn[,-c(1,3,4)]

posmo_cnn$transport_mode[posmo_cnn$transport_mode == 'Bike'] <- '1'
posmo_cnn$transport_mode[posmo_cnn$transport_mode == 'Bus'] <- '2'
posmo_cnn$transport_mode[posmo_cnn$transport_mode == 'Car'] <- '3'
posmo_cnn$transport_mode[posmo_cnn$transport_mode == 'Train'] <- '4'
posmo_cnn$transport_mode[posmo_cnn$transport_mode == 'Tram'] <- '5'
posmo_cnn$transport_mode[posmo_cnn$transport_mode == 'Walk'] <- '6'
posmo_cnn$transport_mode <- as.numeric(posmo_cnn$transport_mode, na.omit = T)


```

```{r}
set.seed(100)
posmo_clust <- posmo_cnn[,c(3,7)]
posmo_clust <- scale(posmo_clust)


# Perform k-means clustering
num_clusters <- 6  # Number of clusters
clustering <- kmeans(posmo_clust, centers = num_clusters, algorithm = "Forgy")

# Get the cluster assignments
cluster_result <- data.frame(posmo_cnn[1], clustering$cluster, iter.max = 50)


cluster_result$transport_mode[cluster_result$transport_mode == '1'] <- 'Bike'
cluster_result$transport_mode[cluster_result$transport_mode == '2'] <- 'Bus'
cluster_result$transport_mode[cluster_result$transport_mode == '3'] <- 'Car'
cluster_result$transport_mode[cluster_result$transport_mode == '4'] <- 'Train'
cluster_result$transport_mode[cluster_result$transport_mode == '5'] <- 'Tram'
cluster_result$transport_mode[cluster_result$transport_mode == '6'] <- 'Walk'






# cluster$labelClust[cluster$labelClust == '1'] <- 'Bike'
# cluster$labelClust[cluster$labelClust == '2'] <- 'Bus'
# cluster$labelClust[cluster$labelClust == '3'] <- 'Car'
# cluster$labelClust[cluster$labelClust == '4'] <- 'Train'
# cluster$labelClust[cluster$labelClust == '5'] <- 'Tram'
# cluster$labelClust[cluster$labelClust == '6'] <- 'Walk'
# 
# cluster$transport_mode[cluster$transport_mode == '1'] <- 'Bike'
# cluster$transport_mode[cluster$transport_mode == '2'] <- 'Bus'
# cluster$transport_mode[cluster$transport_mode == '3'] <- 'Car'
# cluster$transport_mode[cluster$transport_mode == '4'] <- 'Train'
# cluster$transport_mode[cluster$transport_mode == '5'] <- 'Tram'
# cluster$transport_mode[cluster$transport_mode == '6'] <- 'Walk'

# posmo_clust_p$transport_mode[posmo_clust_p$transport_mode == '1'] <- 'Bike'
# posmo_clust_p$transport_mode[posmo_clust_p$transport_mode == '2'] <- 'Bus'
# posmo_clust_p$transport_mode[posmo_clust_p$transport_mode == '3'] <- 'Car'
# posmo_clust_p$transport_mode[posmo_clust_p$transport_mode == '4'] <- 'Train'
# posmo_clust_p$transport_mode[posmo_clust_p$transport_mode == '5'] <- 'Tram'
# posmo_clust_p$transport_mode[posmo_clust_p$transport_mode == '6'] <- 'Walk'


```

```{r}
# cluster <- cluster_result |>
#   group_by(clustering.cluster)
# 
# #Add count n
# cluster <- cluster |>
#   group_by(clustering.cluster, transport_mode)|>
#   tally()
# 
# cluster$labelClust <- NA
# 
# for (i in 1:6){
#   cluster_temp <- cluster |> filter(clustering.cluster == i)
#   label <- cluster_temp$transport_mode[which.max(cluster_temp$n)]
#   print(label)
#   cluster$labelClust[cluster_temp$transport_mode == i] <- label
# }
```

```{r}
# Map Cluster to Transport Mode
cluster_result$clustering.cluster[cluster_result$clustering.cluster == '1'] <- 'Bike'
cluster_result$clustering.cluster[cluster_result$clustering.cluster == '2'] <- 'Car'
cluster_result$clustering.cluster[cluster_result$clustering.cluster == '3'] <- 'Train'
cluster_result$clustering.cluster[cluster_result$clustering.cluster == '4'] <- 'Bus'
cluster_result$clustering.cluster[cluster_result$clustering.cluster == '5'] <- 'Walk'
cluster_result$clustering.cluster[cluster_result$clustering.cluster == '6'] <- 'Tram'

input_plot <- ggplot(cluster_result, aes(transport_mode)) + 
  geom_bar(color = "gray") +
  labs(x = "Transportation Mode", y = "Frequency", title = "Histogram of Ground Truth") +
  ylim(0, 4200)



# Print the cluster assignments
output_plot <- ggplot(cluster_result) + 
  geom_bar(aes(clustering.cluster),color = "gray") +
  labs(x = "Transportation Mode", y = "Frequency", title = "Histogram of Cluster Result") +
  ylim(0, 4200)

ggsave("plots/input_plot.png", plot = input_plot, width = 4, height = 6, dpi = 300)
ggsave("plots/output_plot.png", plot = output_plot, width = 4, height = 6, dpi = 300) 
output_plot
input_plot


```
```{r confusion matrix}
cluster_result <- na.omit(cluster_result)
(confusion_matrix <- table(cluster_result$transport_mode, cluster_result$clustering.cluster, dnn=c("Predicted, Observed")))
```
```{r Overall Accuracy}
sum(diag(confusion_matrix))/sum(confusion_matrix)
```


```{r CNN Model}
# set.seed(100)
# # Create Training and Test data set
# data_rows <- floor(0.80*nrow(posmo_cnn))
# train_indices <- sample(c(1:nrow(posmo_cnn)), data_rows)
# train_data <- posmo_cnn[train_indices,]
# test_data <- posmo_cnn[-train_indices,]
# 
# model <- neuralnet((transport_mode == 1) + (transport_mode == 2) + (transport_mode == 3) + 
#                      (transport_mode == 4) + (transport_mode == 5) + (transport_mode == 6) ~ velocity + sinuosity,
#                   data = train_data,
#                   hidden = c(3,2),
#                   lifesign.step = 1000,
#                   linear.output = T)
# 
# 
```

```{r prediction}

# pred <- predict(model, test_data, rep = 1)
# 
# labels <- unique(posmo_cnn$transport_mode)
# prediction_label <- data.frame(max.col(pred)) |>
#   mutate(pred = labels[max.col.pred.]) |>
#   select(2) |>
#   unlist()
# 
# table(test_data$transport_mode, prediction_label)

```

```{r}
(unique(posmo_truth$transport_mode))

```

# 6. Evaluation

# Visualisation
```{r vis}
visual <- data.frame(st_coordinates(posmo_truth), posmo_truth$velocity, posmo_truth$acceleration, posmo_truth$sinuosity)

visual|> ggplot() +
  geom_point(aes(X,Y,color = posmo_truth.velocity))

visual|> ggplot() +
  geom_point(aes(X,Y,color = posmo_truth.acceleration))

visual|> ggplot() +
  geom_point(aes(X,Y,color = posmo_truth.sinuosity))

ggplot(posmo_truth, aes(id,sinuosity)) +
  geom_point()

cluster_result <- mutate(cluster_result, id = row_number())
posmo_truth <- mutate(posmo_truth, id = row_number())

cluster_join <- left_join(cluster_result, posmo_truth, by = "id" )

cluster_join$correct <- cluster_join$clustering.cluster == cluster_join$transport_mode.x
cluster_join <- data.frame(cluster_join,st_coordinates(posmo_truth))
map_plot <- ggplot(cluster_join) +
  geom_point(aes(X, Y, colour = correct), size = 1, alpha = 0.2)

truefalse <- ggplot(cluster_join)+
  geom_bar(aes(correct, fill = correct))

ggsave("plots/truefalse.png", plot = truefalse, width = 8, height = 6, dpi = 300)
ggsave("plots/map_plot.png", plot = map_plot, width = 8, height = 6, dpi = 300)
  
```
```{r 10-fold cross validation}
# library(cluster)
# library(caret)
# library(lattice)
# 
# 
# # Generate synthetic data with two classes
# set.seed(123)
# data <- rbind(matrix(rnorm(100, mean = -2), ncol = 2),
#               matrix(rnorm(100, mean = 2), ncol = 2))
# labels <- c(rep("Class A", 100), rep("Class B", 100))
# 
# # Define the number of folds for cross-validation
# num_folds <- 10
# 
# # Create stratified cross-validation folds
# folds <- data.frame(createDataPartition(labels, p = 0.8, list = FALSE))
# 
# # Initialize vectors to store cluster labels and accuracy scores
# cluster_labels <- rep(NA, length(labels))
# accuracy_scores <- numeric(num_folds)
# 
# # Perform cross-validation
# for (fold in 1:num_folds) {
#   # Obtain the training and test data for the current fold
#   train_data <- data[folds$Resample1[-fold], ]
#   train_labels <- labels[folds$Resample1[-fold]]
#   test_data <- data[folds$Resample1[fold], ]
#   test_labels <- labels[folds$Resample1[fold],]
#   
#   # Perform clustering using k-means algorithm on the training data
#   k <- 2
#   kmeans_result <- kmeans(train_data, centers = k, nstart = 10)
#   
#   # Assign cluster labels to the test data using majority voting
#   test_clusters <- kmeans(test_data, centers = kmeans_result$centers)$cluster
#   test_cluster_labels <- rep(NA, length(test_clusters))
#   
#   for (i in 1:k) {
#     cluster_indices <- which(test_clusters == i)
#     test_cluster_labels[cluster_indices] <- as.character(tables:::vec_counts(train_labels[cluster_indices])$key[1])
#   }
#   
#   # Evaluate accuracy for the current fold
#   accuracy_scores[fold] <- sum(test_cluster_labels == test_labels) / length(test_labels)
#   
#   # Store cluster labels for all data points
#   cluster_labels[folds$Resample1[fold]] <- test_cluster_labels
# }
# 
# # Compute average accuracy across all folds
# average_accuracy <- mean(accuracy_scores)
# 
# # Print results
# print("Cluster Labels:")
# print(cluster_labels)
# print(paste("Average Accuracy:", round(average_accuracy, 2)))
#

```

=======
---
title: The title of your Semesterproject
subtitle: A subtle subtitle
author: Cyril Geistlich and Micha Franz
output: html
editor: visual
  markdown: 
    wrap: 72
---

<!-- You can add  your R Code with Code chunks-->

```{r}
#| echo: false
#| warning: false
#| message: false

# You can set chunk options individually per code chunk, as was done with this
# code chunk.

# echo: false           hides the code from the generated output
# warning: false        hides warnings from the generated output
# message: false        hides messages from the generated output

# To apply the setting for all code chunks, add the options to the yaml header of the document (in between the ---) without the preceeding "#|".

```

## Abstract

This project aims to investigate key factors and features in GPS tracking data to differentiate transportation vehicles. Machine learning is applied to automate transportation mode detection using spatial, temporal, and attribute analysis. Manual verification of results ensures accuracy. The findings contribute to computational movement analysis and automated transportation mode detection.

## Introduction

## Research Question

What are the key factors and features that can be extracted from GPS tracking data to differentiate between different types of transportation modes? How can machine learning techniques be applied to GPS tracking data to automate the detection of the mode of transportation and which accuracies can be achieved by different machine learning algorithms?

## Material and Methods

<!-- the following is just a placeholder text, remove it!-->

### Removing false movement and static points

When tracking a person throughout the day using GPS data, there are instances where the person appears to be stationary, such as when in an office or at a university. However, due to GPS inaccuracies, these stationary points may not appear at the exact same location and can exhibit erratic movement patterns. The accuracy of GPS signals is often compromised in dense buildings, amplifying this phenomenon. As a result, parameters like velocity and step length can show values that are typically associated with other categories. To address this issue, two approaches have been employed. 

The first approach involves analyzing the angles between consecutive points. Typically, these angles are significantly smaller for stationary points compared to other movements. By visually determining a threshold angle (X), the dataset is filtered to remove all data points with angles smaller than X. This process needs to be repeated iteratively until no angles below the threshold remain, as the removal of data points alters the angles between the remaining points.

The second approach considers the distance between the current point and a set number (X) of preceding and consecutive points. A point is deemed static if the maximum distance between that point and any of the X preceding or consecutive points exceeds a predefined threshold (X). However, this approach may unintentionally remove non-static data points, particularly when a person is walking slowly and numerous data points are recorded within a small distance. Adjusting the distance threshold or the number of preceding and consecutive points can mitigate this issue, but it requires striking a balance between filtering out false movements and retaining genuine data.

Finding the optimal compromise between these filtering approaches involves considering the specific characteristics of the tracked person's movements and the quality of the GPS data. By iteratively applying the angle-based filtering and analyzing the distance to surrounding points, a more accurate identification of stationary periods can be achieved, mitigating the impact of GPS inaccuracies and preserving the integrity of the tracking data.

## Results

<!-- the following is just a placeholder text, remove it!-->

Philosophy oneself passion play fearful self noble zarathustra deceptions sexuality. Endless ocean of oneself dead ocean. Selfish decrepit.

## Discussion

<!-- the following is just a placeholder text, remove it!-->

Justice convictions spirit sexuality insofar free marvelous joy. Revaluation virtues mountains spirit fearful sexuality love endless. Society intentions will noble burying aversion moral. Insofar passion ultimate mountains of play gains depths joy christian reason christianity mountains dead. Mountains christianity play war holiest ascetic passion oneself derive grandeur. Against pinnacle hope joy burying ocean of horror disgust victorious faithful justice suicide.

## Code

```{r, warning = F}
library("dplyr")
library("sf")
library("readr") 
library("ggplot2")
library("mapview")
library("lubridate")
library("zoo") 
library("caret")
library("neuralnet")
library("mlbench")
# library("keras")
# library("tensorflow")
library("LearnGeom") # to calculate angle
library("randomForest")
library("geosphere") # to calculate distances
library("RColorBrewer") # to create custom color palettes
library("ggcorrplot")
```

## supporting functions

```{r}
custom_mapview <- function(sf_object){
  mapview(sf_object, cex = 4, col.regions = "#700101")
}

# creates lines out of points for visualisation purposes
point2line <- function(points){
  geometries <- st_cast(st_geometry(points %>% select(geometry)), "POINT")
  n <- length(geometries) - 1
  linestrings <- lapply(X = 1:n, FUN = function(x) {

  pair <- st_combine(c(geometries[x], geometries[x + 1]))
  line <- st_cast(pair, "LINESTRING")
  return(line)
  })
  
  multilinetring <- st_multilinestring(do.call("rbind", linestrings))
  
  df <- data.frame(linestrings[1])
  
  for (i in 2:length(linestrings)){
    temp <- data.frame(linestrings[i])
    df <-  rbind(df, temp) 
  }
  sf_lines <- df %>% st_as_sf()
}

un_col <- function(df){
  return(length(unique(df)))
}
```

# 1. Data Prep

## 1.1 Read Data

```{r read tracking data}
#posmo_truth_csv <- read.delim("data/posmo_full.csv",sep=",")
posmo_micha_truth_csv <- read.delim("data/manually_labelled/posmo_20230502_to_20230613_m.csv",sep=",") 
posmo_micha_csv <- read.delim("data/posmo_labelled/posmo_20230502_to_20230613_p.csv",sep=",") 
```

```{r read context data}

#zvv_sbahn <- st_read("data/zvv_netz/Linien_des_offentlichen_Verkehrs_-OGD.gpkg", layer="ZVV_S_BAHN_LINIEN_L") 

#zvv_tram_bus <- st_read("data/zvv_netz/Linien_des_offentlichen_Verkehrs_-OGD.gpkg", layer="ZVV_LINIEN_GEN_L") 

#seen <- read_sf("data/gewaesser.shp")
```

## 1.2.1 Clean and preprocess data

```{r preprocess data}

# posmo_raw <- read.delim("data/posmo_26_05_2023.csv",sep=",")
# posmo_raw <- st_as_sf(posmo_raw,coords=c("lon_x", "lat_y"), crs = 2056)
#mapview(posmo_truth)

process_posmo_data <- function(posmo_data) { # function with preprocessing steps

  # Convert to sf object
  posmo_data <- posmo_data %>%
    st_as_sf(coords = c("lon_x", "lat_y"), crs = 4326) %>%
    st_transform(crs = 2056)
  
  # Remove unwanted columns
  posmo_data <- posmo_data[, -c(1, 3, 4)]
  
  # Fix Timestamp
  posmo_data$datetime <- ymd_hms(posmo_data$datetime) + hours(2)
  
  # Add ID to rows
  posmo_data <- posmo_data %>%
    mutate(id = row_number())
  
  # remove duplicate time values
  posmo_data <- posmo_data[!duplicated(posmo_data$datetime), ]
  
  # remove subsequent duplicate location (person wasn't moving)
  posmo_data <- posmo_data %>% 
    filter(geometry != lead(geometry))
  
  return(posmo_data)
}

posmo_micha_truth <- process_posmo_data(posmo_micha_truth_csv)

posmo_micha <-  process_posmo_data(posmo_micha_csv)
```

```{r working datasets}
micha_subset <- posmo_micha_truth %>% filter(datetime < ymd("20230506") & datetime > ymd("20230501"))

working_dataset <- micha_subset
```


### 1.2.2 Remove static data points
```{r function to filter static points using moving distance}
filterStaticByDistance <- function(data, threshold_distance, consecutive_points) {
  require(geosphere)
  
  # transform to WGS84, necessary to calculate distance using geosphere
  data <- data %>% st_transform(4326)
  
  # Extract coordinates from the geometry
  coords <- data.frame(st_coordinates(data))
  data$longitude <- coords$X
  data$latitude <- coords$Y
  
  # Calculate distances to preceding and consecutive points
  distances <- numeric(nrow(data))
  for (i in (consecutive_points + 1):(nrow(data) - consecutive_points)) {
    next_points <- coords[(i + 1):(i + consecutive_points), ]
    prev_points <- coords[(i - 1):(i - consecutive_points), ]
    all_points <- rbind(next_points, prev_points)
    distances[i] <- max(geosphere::distGeo(coords[i, ], all_points))
  }
  
  # Filter out points where the maximum distance exceeds the threshold
  filtered_data <- data[distances >= threshold_distance | distances == 0, ] # keep first/last values which are 0
  
  # Transform back to LV95
  filtered_data <- filtered_data %>% st_transform(2056)
  
  return(list(filtered_data = filtered_data, distances = distances)) # distances are just needed for testing thresholds
}
```


```{r Function to calculate angle }
getAngle <- function(coords) {
  angles <- numeric(nrow(coords)) # Initialize angles as a numeric vector
  angles[1] = NA # first point can't have an angle

  for (i in 2:(nrow(coords) - 1)) { # calculate the angle for 3 consecutive points, similar to lag/lead
    angle <- Angle( #function from library LearnGeom
      c(coords[i - 1, "X"], coords[i - 1, "Y"]),
      c(coords[i, "X"], coords[i, "Y"]),
      c(coords[i + 1, "X"], coords[i + 1, "Y"])
    )
    angles[i] <- angle # Assign the calculated angle to the corresponding index in angles
  }
  angles[nrow(coords)] = NA # last point cant have an angle
  return(c(angles))
}
```


```{r function to remove static points by angle}
filterStaticByAngle <- function(working_dataset, angleTreshold){
  coords <- data.frame(st_coordinates(working_dataset), working_dataset$id)  
  working_dataset$angle <- getAngle(coords)
  min_angle <- min(working_dataset$angle, na.rm = T)


  while (min_angle <= angleTreshold) { # iteratively filter out tight angles until none smaller 60 are left
    working_dataset <- working_dataset %>% filter(is.na(angle) | angle > angleTreshold) # exclude first and last value (=NA)
    coords <- data.frame(st_coordinates(working_dataset), working_dataset$id)
    working_dataset$angle <- getAngle(coords)
    min_angle <- min(working_dataset$angle, na.rm = T)
  }
  return(working_dataset)
}
```



```{r Actual removal of static points}
result <- filterStaticByDistance(working_dataset, threshold_distance = 60, consecutive_points = 5)

filteredByDistance <- result$filtered_data
working_dataset$distances <- result$distances # just for testing threshold values
filteredByAngle <- filterStaticByAngle(working_dataset, 60)
filtertedByDistance_and_Angle <- filterStaticByAngle(filteredByDistance, 60)
```

```{r Visualistion of angle removal}
filtered_data_line <- point2line(filtertedByDistance_and_Angle)
filtered_angle_line <- point2line(filteredByAngle)
unfiltered_data_line <- point2line(working_dataset)

pal_blue <- colorRampPalette(c("cyan", "blue"))
pal_orng <- colorRampPalette(c("yellow", "red"))


mapview(working_dataset, alpha.regions=1.0, col.regions = "#901010") +
  mapview(unfiltered_data_line, color="#901010", lwd=2) +
  mapview(filtertedByDistance_and_Angle, alpha.regions=1.0, col.regions="#008940") +
  mapview(filtered_data_line, color="#008940", lwd=2) 


mapview(working_dataset, alpha.regions=1.0, col.regions = "#901010", cex=4) +
  mapview(unfiltered_data_line, color="#901010", lwd=2) +
  mapview(filteredByAngle, alpha.regions=1.0, col.regions="orange", cex=4) +
  mapview(filtered_angle_line, color="orange", lwd=2) 

mapview(filtered_data_line, color="#008940", lwd=2) +
  mapview(unfiltered_data_line, color="#901010", lwd=2)
  
```


## 1.3 Segmentation?

## 1.4 Calculate Movement Parameters

### 1.4.1 Speed/ Additional Moving Window Speed?

```{r Calc Diff_s, steplength, velocity}
#Create Coord Column
coords <- data.frame(st_coordinates(working_dataset), working_dataset$id)

#Calculate Time Difference between steps (diff_s), steplenght and velocity. 
working_dataset <- working_dataset |> 
  mutate(diff_s = as.numeric(difftime(lead(datetime),datetime))) |>
  mutate(steplength = ((coords$X - lead(coords$X))^2 + (coords$Y - lead(coords$Y))^2)^0.5) |>
  mutate(velocity = as.numeric(steplength/diff_s)) |>
  filter(diff_s != 0)

coords <- data.frame(st_coordinates(working_dataset), working_dataset$id)

#Calculate Moving Window Step length
working_dataset <- working_dataset |>
  mutate(
    step_mean = rowMeans(
      cbind(
        sqrt((lag(coords$X, 3) - coords$X)^2 + (lag(coords$Y, 3) - coords$Y)^2),
        sqrt((lag(coords$X, 2) - coords$X)^2 + (lag(coords$Y, 2) - coords$Y)^2),
        sqrt((lag(coords$X, 1) - coords$X)^2 + (lag(coords$Y, 1) - coords$Y)^2),
        sqrt((coords$X - lead(coords$X, 1))^2 + (coords$Y - lead(coords$Y, 1))^2),
        sqrt((coords$X - lead(coords$X, 2))^2 + (coords$Y - lead(coords$Y, 2))^2),
        sqrt((coords$X - lead(coords$X, 3))^2 + (coords$Y - lead(coords$Y, 3))^2)
      )
    )
  )


#Calculate Moving Window diff_s
working_dataset <- working_dataset |>
  mutate(diff_s_mean = as.numeric(difftime(lead(datetime,3),lag(datetime,3)))/6)


#Calculate Moving Window velocity
working_dataset <- working_dataset |>
  mutate(velocity_mean = as.numeric(step_mean/diff_s_mean))
 
# Delete Infitinte Values (is there better solution?)
#working_dataset$velocity <- working_dataset$velocity[!is.infinite(working_dataset$velocity)]
coords <- data.frame(st_coordinates(working_dataset), working_dataset$id)


```

### 1.4.2 Acceleration /Moving Window?

```{r Acceleration}
#Acceleration stepwise
working_dataset$acceleration <- working_dataset$velocity/lag(working_dataset$diff_s)

# Calculate acceleration using a moving window
working_dataset <- working_dataset |>
  mutate(
    acceleration_mean = rowMeans(
      cbind(
        lag(working_dataset$acceleration,3),
        lag(working_dataset$acceleration,2),
        lag(working_dataset$acceleration,1),
        working_dataset$acceleration,
        lead(working_dataset$acceleration,1),
        lead(working_dataset$acceleration,2),
        lead(working_dataset$acceleration,3)
      )
    )
  )


```

### 1.4.3 Sinuosity /Moving Window?

```{r Sinuosity}
# Calculate Sinuosity using moving step_mean as path length and euclidean distance between


working_dataset <- working_dataset |>
  mutate(
    sinuosity = 
      ( # Path Length/Direct distance between first and last point
        sqrt((lag(coords$X, 3) - lag(coords$X, 2))^2 + (lag(coords$Y, 3) - lag(coords$Y, 2))^2) +
        sqrt((lag(coords$X, 2) - lag(coords$X, 1))^2 + (lag(coords$Y, 2) - lag(coords$Y, 1))^2) +
        sqrt((lag(coords$X, 1) - coords$X)^2 + (lag(coords$Y, 1) - coords$Y)^2) +
        sqrt((coords$X - lead(coords$X, 1))^2 + (coords$Y - lead(coords$Y, 1))^2) +
        sqrt((lead(coords$X, 1) - lead(coords$X, 2))^2 + (lead(coords$Y, 1) - lead(coords$Y, 2))^2) +
        sqrt((lead(coords$X, 2) - lead(coords$X, 3))^2 + (lead(coords$Y, 2) - lead(coords$Y, 3))^2)
      ) 
      / sqrt((lag(coords$X, 3) - lead(coords$X, 3))^2 + (lag(coords$Y, 3) - lead(coords$Y, 3))^2)
  ) 


```




### 1.4.5 Closeness to Traffic Network

### 1.4.6 Water Bodies (For boats)

### 1.4.7 Slope?

### 1.4.8 Average Distance between points in section

### Further Parameters!


## Clean Data

```{r}
# Replace NA values with a specified value (e.g., mean, median, or 0)
working_dataset[is.na(working_dataset)] <- 0  # Replace NA with 0


velocity_plot <- ggplot(working_dataset, aes(id,velocity)) +
  geom_point() +
  ylab("velocity [m/s]")

acceleration_plot <- ggplot(working_dataset, aes(id,acceleration)) +
  geom_point() +
  ylab("acceleration [m/s2]")

sinuosity_plot <- ggplot(working_dataset, aes(id,sinuosity)) +
  geom_point()

# ggsave("plots/velocity_plot.png", plot = velocity_plot, width = 8, height = 6, dpi = 300)
# ggsave("plots/acceleration_plot.png", plot = acceleration_plot, width = 8, height = 6, dpi = 300)
# ggsave("plots/sinuosity_plot.png", plot = sinuosity_plot, width = 8, height = 6, dpi = 300)
```

```{r}
working_dataset_copy <- working_dataset
```

# 2.PCA?

```{r}
# select columns with relevant variable and standardize them
standardized <- working_dataset[, 5:14] %>% 
  st_drop_geometry() %>%
  scale(center = TRUE, scale = TRUE) %>%
  as.data.frame()


corr_matrix <- cor(standardized)
ggcorrplot(corr_matrix)

data_pca <- princomp(corr_matrix)

test <- data_pca$loadings

scores <- as.data.frame(data_pca$scores)
```


# 3. Categories

Stationary? Walk (Running?) Bike Train Tram Bus Car Skateboard E-Scooter Boat Other
>>>>>>> 6b784b9407802dc48e6d071f5918fa4009ed7913
